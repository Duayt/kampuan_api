{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00a8dd30f3ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkampuan\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects_src/kampuan_api/src/kampuan/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msyllable_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkampuan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_vowel_form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects_src/kampuan_api/src/kampuan/lang_tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkampuan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdf_vowel_form\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHAI_TONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects_src/kampuan_api/src/kampuan/const.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m df_init_con = pd.read_excel(os.path.join(dirname,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                          'assets/initial_consonants.xlsx'), skiprows=1).fillna(method='ffill')\n\u001b[1;32m      9\u001b[0m df_fin_con = pd.read_excel(os.path.join(dirname,\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/my_chat_bot/lib/python3.8/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# files that xlrd can parse don't start with the expected signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'xls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_FORMAT_DESCRIPTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'; not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     bk = open_workbook_xls(\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "import kampuan as kp\n",
    "\n",
    "kp.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phrase='สวัสดี'\n",
    "kp.tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp.tokenize('ตลาด')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2 word 2 syllabus case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_1 ={'กินข้าว':'กาวขิ้น',\n",
    "         'หิวจัง':'หังจิว',\n",
    "        'คำผวน':'ควนผำ',\n",
    "        'นอนแล้ว':'แนวร้อน',\n",
    "        'ตะปู':'ตูปะ',\n",
    "        'นักเรียน':'เนียนรัก',\n",
    "        'ขนม':'ขมหน่ะ'}\n",
    "\n",
    "tmp=[kp.tokenize(key) for key in case_1.keys()]\n",
    "tmp\n",
    "\n",
    "# get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Position:\n",
    "    name: str\n",
    "    lon: float\n",
    "    lat: float\n",
    "\n",
    "@dataclass\n",
    "class Capital(Position):\n",
    "    country: str\n",
    "from enum import Enum\n",
    "\n",
    "class Color(Enum):\n",
    "    red = 1\n",
    "    green = 2\n",
    "    blue = 3\n",
    "    \n",
    "@dataclass\n",
    "class Test:\n",
    "    _name: str=\"schbell\"\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    @name.setter\n",
    "    def name(self, v: str) -> None:\n",
    "        self._name = v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subwords\n",
    "\n",
    "* initial_consonant\n",
    "    * single อักษรเดี่ยว\n",
    "        * sound_level (low/mid/high)\n",
    "        * low_single, low_double\n",
    "    * cluster อักษรควบ\n",
    "        * true_cluster อักษรควบแท้\n",
    "        * fasle_cluster อักษรควบไม่แท้\n",
    "    * leading_cluster อักษรนำ–อักษรตาม\n",
    "        * hornum_leading หอ นำ\n",
    "        * oarnum_leading ออ นำ\n",
    "        * non_conform_leading นำด้วยสูง หรือ กลาง  นคร ขนม\n",
    "* final_consonant\n",
    "    * type (dead/live)\n",
    "    * sound (eng)\n",
    "        * k: กก\n",
    "        * ng: กง\n",
    "        * t: กด\n",
    "        * m: กม\n",
    "        * n: กน\n",
    "        * p: กบ\n",
    "        * y: เกย\n",
    "        * v: เกอว\n",
    "    * sound_level low/mid/high\n",
    "* vowel\n",
    "* tone http://www.thai-language.com/ref/tone-rules\n",
    "    * tone_mark\n",
    "    * tone_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from kampuan.lang_tools import get_vowel_pattern,get_vowel_form,remove_tone_mark\n",
    "\n",
    "vowel_pattern=get_vowel_pattern()\n",
    "def match_pattern(pattern,text):\n",
    "    m=re.match(pattern,text)\n",
    "    return m\n",
    "\n",
    "def match_vowel_form(text,vowel_patterns):\n",
    "    for i,pattern in enumerate(vowel_patterns):\n",
    "        m=re.match(pattern,text)\n",
    "        if m:\n",
    "            return (i,m,pattern)\n",
    "    \n",
    "    return (-1,text,text)\n",
    "        \n",
    "vowel_forms=get_vowel_form(REP='-')\n",
    "test_text =['เขียว',\n",
    "            'เกรียน',\n",
    "            'ตู่',\n",
    "            'ตด',\n",
    "            'กร',\n",
    "            'นอน',\n",
    "           'ขนุน',\n",
    "           'จัง',\n",
    "           'กำ',\n",
    "           'ใหญ่',\n",
    "            'ใคร',\n",
    "           'เดา',\n",
    "           'เปรต',\n",
    "           'เสร็จ',\n",
    "           'ปีน',\n",
    "           'เปี๊ยะ',\n",
    "           'คั่ว',\n",
    "           'แก้ม',\n",
    "            'แช่ง',\n",
    "            'แกล้ม',\n",
    "            'แพร่',\n",
    "           'แข็ง',\n",
    "           'เกลอ',\n",
    "           'เทอญ',\n",
    "           'เกิด',\n",
    "           'เตลิด',\n",
    "           'กลม',\n",
    "            'เลว',\n",
    "            'เสก',\n",
    "           'วัว',\n",
    "           'เยี่ยม',\n",
    "           'เพลง',\n",
    "           'ปลอม',\n",
    "           'หอม',\n",
    "           'เวร',\n",
    "           'อย่าง',\n",
    "           'อยู่',\n",
    "           'อย่า',\n",
    "           'กวน' ,\n",
    "           'แวว',\n",
    "           'วน',\n",
    "           'ว่าย',\n",
    "           'สวย',\n",
    "           'เขย']\n",
    "\n",
    "for text in test_text:\n",
    "    print(text)\n",
    "    plain=remove_tone_mark(text)\n",
    "    (i,m,pattern)=match_vowel_form(plain)   \n",
    "    print('===')\n",
    "    print(m.groups(),vowel_forms[i],pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kampuan.const import THAI_VOW\n",
    "\n",
    "len(THAI_VOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case เ แ need to verify ควบกล้ำ \n",
    "# 1 ตัว -> no สะกด\n",
    "# 2 ตัว -> 1 สะกด\n",
    "# 3 ตัว -> 1 สะกด\n",
    "\n",
    "# อักษรนำ\n",
    "\n",
    "# #initialize the special character cases\n",
    "# #คำควบแท้\n",
    "# self.two_char_combine = ['กร','กล', 'กว', 'คร', 'ขร', 'คล', 'ขล','คว', 'ขว', 'ตร', 'ปร', 'ปล', 'พร', 'พล' ,'ผล',\n",
    "#            'บร','บล','ดร','ฟร','ฟล','ทร','จร','ซร','ปร','สร']\n",
    "# #คำนำ\n",
    "# self.lead_char_nosound = ['อย','หง','หญ','หน','หม','หย', 'หร','หล','หว']\n",
    "# #อักษรสูงนำอักษรต่ำ\n",
    "# self._lead_char_high_low = ['ขน', 'ขม','สม','สย','สน','ขย','ฝร','ถล','ผว','ตน','จม','ตล',]\n",
    "# #อักษรสูงนำอักษรกลาง\n",
    "# self._high_char_high_medium = ['ผท','ผด','ผก','ผอ','ผช']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythainlp.thai_tonemarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythainlp.thai_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pythainlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4cf74004ddf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthai_below_vowels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pythainlp' is not defined"
     ]
    }
   ],
   "source": [
    "['-'+char for char in pythainlp.thai_below_vowels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pythainlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-70b992b70aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthai_tonemarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pythainlp' is not defined"
     ]
    }
   ],
   "source": [
    "['_'+char for char in pythainlp.thai_tonemarks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ั', '_ิ', '_ี', '_ึ', '_ื', '_ํ', '_็']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['_'+char for char in pythainlp.thai_above_vowels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['เ_', 'แ_', 'โ_', 'ใ_', 'ไ_']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char+'_' for char in pythainlp.thai_lead_vowels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ะ', '_า', '_ำ', '_ๅ']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['_'+char for char in pythainlp.thai_follow_vowels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ฤฦะัาำิีึืุูเแโใไๅํ็'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythainlp.thai_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Optional,List\n",
    "class TestWord(NamedTuple):\n",
    "    raw: str\n",
    "    vowel_form: Optional[str]=None\n",
    "    tone_mark: Optional[str]=None\n",
    "    all_consonants: Optional[List[str]]=None\n",
    "\n",
    "\n",
    "a = TestWord('เขียว','เ-ีย',None,['ข','ย','ว'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list=[\n",
    "TestWord('เขียว', 'เ-ีย', None, ['ข', 'ย', 'ว']),\n",
    "TestWord('เขียว', 'เ-ีย', None, ['ข', 'ย', 'ว']),\n",
    "TestWord('เขียว', 'เ-ีย'),\n",
    "TestWord('เขียว', 'เ-ีย', None, ['ข', 'ย', 'ว']),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pythainlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8a674c39173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pythainlp'"
     ]
    }
   ],
   "source": [
    "import pythainlp\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ThaiSubWord:\n",
    "    def __init__(self, word:str='เกี๊ยว'):\n",
    "        # Character base\n",
    "        self._raw: str=word\n",
    "        self._vowels:List[str]=self.vowels\n",
    "        self._consonants:List[str]=self.consonants\n",
    "        self._tone_mark:List[str]=self.tone_mark\n",
    "        \n",
    "        # Type based\n",
    "        self._inti_con:str =None\n",
    "        self._final_con:str=None\n",
    "        self._vowel_form:str=None\n",
    "        self._tone:str=None\n",
    "    \n",
    "    @property\n",
    "    def raw(self):\n",
    "        return self._raw\n",
    "    \n",
    "    @property\n",
    "    def vowels(self):\n",
    "        return [char for char in self._raw if char in THAI_VOW]\n",
    "    \n",
    "    @property\n",
    "    def consonants(self):\n",
    "        return [char for char in self._raw if char in THAI_CONS]\n",
    "    \n",
    "    @property\n",
    "    def tone_mark(self):\n",
    "        return [char for char in self._raw if char in THAI_TONE]\n",
    "    \n",
    "        \n",
    "\n",
    "a=ThaiSubWord('สลิ่ม')\n",
    "\n",
    "a.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.thai-language.com/ref/tone-rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tien's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kampuan.util.extract import thai_subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'หว'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[thai_subwords(orig_word=syll) for syll in kp.puan_kam(phrase)]\n",
    "x[0].start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thai_match_pattern():\n",
    "    def __init__(self, start_regex, vowel_regex, end_regex, sound_regex):\n",
    "        self.start_regex = start_regex\n",
    "        self.vowel_regex = vowel_regex\n",
    "        self.end_regex = end_regex\n",
    "        self.sound_regex = sound_regex\n",
    "        \n",
    "    def match_start(self, orig_word):        \n",
    "        matches = re.findall(self.start_regex, orig_word, re.DOTALL)\n",
    "        return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference https://www.geeksforgeeks.org/longest-common-substring-dp-29/\n",
    "# Returns length of longest common  \n",
    "# substring of X[0..m-1] and Y[0..n-1]  \n",
    "def LCSubStr(X, Y, m, n): \n",
    "      \n",
    "    # Create a table to store lengths of \n",
    "    # longest common suffixes of substrings.  \n",
    "    # Note that LCSuff[i][j] contains the  \n",
    "    # length of longest common suffix of  \n",
    "    # X[0...i-1] and Y[0...j-1]. The first \n",
    "    # row and first column entries have no \n",
    "    # logical meaning, they are used only \n",
    "    # for simplicity of the program. \n",
    "      \n",
    "    # LCSuff is the table with zero  \n",
    "    # value initially in each cell \n",
    "    LCSuff = [[0 for k in range(n+1)] for l in range(m+1)] \n",
    "      \n",
    "    # To store the length of  \n",
    "    # longest common substring \n",
    "    result = 0 \n",
    "  \n",
    "    # Following steps to build \n",
    "    # LCSuff[m+1][n+1] in bottom up fashion \n",
    "    for i in range(m + 1): \n",
    "        for j in range(n + 1): \n",
    "            if (i == 0 or j == 0): \n",
    "                LCSuff[i][j] = 0\n",
    "            elif (X[i-1] == Y[j-1]): \n",
    "                LCSuff[i][j] = LCSuff[i-1][j-1] + 1\n",
    "                result = max(result, LCSuff[i][j]) \n",
    "            else: \n",
    "                LCSuff[i][j] = 0\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class thai_subwords():\n",
    "    \"\"\"Design to take input as single Thai token or word and extract start, vowel, end and sound of said token\n",
    "    For additional data regarding different Thai words types and pronunciations, \n",
    "    consult:https://sites.google.com/site/phasathaionline/hnwy-kar-reiyn-ru2/phyaychnatn\"\"\"\n",
    "    def __init__(self, orig_word, debug=False):\n",
    "        self.orig_word = orig_word #Try not to change this value\n",
    "        self._start = ''\n",
    "        self._vowel = ''\n",
    "        self._end = ''\n",
    "        self._sound = ''\n",
    "        self._double_start_sound = False #used to flag with that has two starting alphabets with sound like 'ตลาด = ตะ ลาด'\n",
    "        self._high_lead_low = False #case อักษรสูงนำอักษรต่ำ\n",
    "        self.debug = debug\n",
    "        \n",
    "        #Need to deal with negative lookahead case for word like \"เกรียน\" to correctly extract กร\n",
    "        self.vowels_form = ['ะ', ' ั' ' ็', 'า', ' ิ' , ' ่' , \" ่\" , ' ํ', ' ุ', ' ู', 'เ', 'ใ', 'ไ', 'โ', 'อ', 'ย', 'ว', 'ฤ', 'ฤๅ', 'ฦ', 'ฦๅ']\n",
    "        combine_vowel_regex_1 = '(?!เ.{1,4}ี.*ย)(?!เ.{1,4}ี.*ยะ)(?!เ.{1,4}ื.*อ)(?!เ.{1,4}ื.*อะ)(?!เ.{1,4}.*อะ)(?!เ.{1,4}.*อ)(?!เ.{1,4}.*าะ)'\n",
    "        combine_vowel_regex_2 = '(?!เ.{1,4}.*า)(?!แ.{1,4}.*า)(?!.{1,4}ัวะ)(?!โ.{1,4}.*ะ)'\n",
    "        combine_vowel_regex = combine_vowel_regex_1 + combine_vowel_regex_2\n",
    "        self.start_regex_1 = ['(.{1,4})ะ','(.{1,4})า', '(.{1,4})ิ.*', '(.{1,4})ี.*', '(.{1,4})ึ', '(.{1,4})ื.*', '(.{1,4})ุ.*', '(.{1,4})ู.*', 'เ(.{1,4})็', \n",
    "                            'เ(.{1,4}).*', '(.{1,4}).*อ','แ(.{1,4}).*', '(.{1,4})ั.*', 'โ(.{1,4}).*', '(.{1,4}).*ำ', 'ใ(.{1,4}).*', 'ไ(.{1,4})']\n",
    "        self.start_regex_1  = [combine_vowel_regex+regex for regex in self.start_regex_1]\n",
    "        self.start_regex_2 = ['เ(.{1,4})ี.*ยะ', 'เ(.{1,4})ี.*ย', 'เ(.{1,4})ื.*อะ', 'เ(.{1,4})ื.*อ', 'เ(.{1,4}).*อ', 'เ(.{1,4}).*อะ',\n",
    "                              'เ(.{1,4}).*า',\n",
    "                              'เ(.{1,4}).*าะ','แ(.{1,4}).*ะ','(.{1,4})ัวะ','โ(.{1,4}).*ะ', 'เ(.{1,4})็', 'เ(.{1,4})ิ.*']\n",
    "        self.end_regex_1 = ['\\[REP\\]า(.{1,4})', '\\[REP\\]ิ(.{1,4})', '\\[REP\\]ี(.{1,4})', '\\[REP\\]ึ(.{1,4})', '\\[REP\\]ือ(.{1,4})', \n",
    "                            '\\[REP\\]ุ(.{1,4})', '\\[REP\\]ู(.{1,4})', 'เ\\[REP\\]็(.{1,4})', 'เ\\[REP\\](.{1,4})', '\\[REP\\]อ(.{1,4})',\n",
    "                            'แ\\[REP\\](.{1,4})', '\\[REP\\]ั(.{1,4})', 'โ\\[REP\\](.{1,4})','\\[REP\\]ำ(.{1,4})', 'ใ\\[REP\\](.{1,4})', \n",
    "                            'ไ\\[REP\\](.{1,4})']\n",
    "        self.end_regex_2 = ['เ\\[REP\\]ีย(.{1,4})', 'เ\\[REP\\]ือ(.{1,4})', 'เ\\[REP\\]อ(.{1,4})', 'เ\\[REP\\]อะ(.{1,4})','เ\\[REP\\]า(.{1,4})']\n",
    "        \n",
    "        self.start_regex  = self.start_regex_1 + self.start_regex_2 \n",
    "        self.end_regex  = self.end_regex_1 + self.end_regex_2 \n",
    "        #self.vowel_regex = vowel_regex\n",
    "        #self.end_regex = end_regex\n",
    "        self.sound_regex = ['(่)', '(้)', '.(๊)','()๋']\n",
    "        \n",
    "        #initialize the special character cases\n",
    "        #คำควบแท้\n",
    "        self.two_char_combine = ['กร','กล', 'กว', 'คร', 'ขร', 'คล', 'ขล','คว', 'ขว', 'ตร', 'ปร', 'ปล', 'พร', 'พล' ,'ผล',\n",
    "                   'บร','บล','ดร','ฟร','ฟล','ทร','จร','ซร','ปร','สร']\n",
    "        #คำนำ\n",
    "        self.lead_char_nosound = ['อย','หง','หญ','หน','หม','หย', 'หร','หล','หว']\n",
    "        #อักษรสูงนำอักษรต่ำ\n",
    "        self._lead_char_high_low = ['ขน', 'ขม','สม','สย','สน','ขย','ฝร','ถล','ผว','ตน','จม','ตล',]\n",
    "        #อักษรสูงนำอักษรกลาง\n",
    "        self._high_char_high_medium = ['ผท','ผด','ผก','ผอ','ผช']\n",
    "        \n",
    "        \n",
    "    # using property decorator \n",
    "    @property\n",
    "    def start(self): \n",
    "        #print(\"getter method called\") \n",
    "        temp_start = self.match_pattern(self.orig_word, self.start_regex)\n",
    "        if len(temp_start)==1: return temp_start\n",
    "        else: \n",
    "            return self.check_double_start_alphabets(temp_start)\n",
    "        #return self.match_pattern(self.orig_word, self.start_regex)\n",
    "    \n",
    "    @property\n",
    "    def sound(self):\n",
    "        if self.match_pattern(self.orig_word, self.sound_regex) is None: return ''\n",
    "        return self.match_pattern(self.orig_word, self.sound_regex)\n",
    "    \n",
    "    @property\n",
    "    def vowel(self):\n",
    "        return self.orig_word.replace(self.sound,'').replace(self.start,'[REP]',1) #[REP] will be used for conversion to Lu/Ru\n",
    "#     def vowel(self):\n",
    "#         return self.orig_word.replace(self.sound,'').replace(self.end,'').replace(self.start,'[REP]',1) #[REP] will be used for conversion to Lu/Ru\n",
    "    \n",
    "    @property #might not need this one in final application as we need vowel\n",
    "    def end(self):\n",
    "        if self.match_pattern(self.vowel, self.end_regex) not in self.vowels_form: \n",
    "            return self.match_pattern(self.vowel, self.end_regex)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "#     # a setter function \n",
    "#     @start.setter \n",
    "#     def start(self): \n",
    "#         print(\"setter method called\") \n",
    "#         self._start = match_pattern(self.start_regex)\n",
    "    \n",
    "    def match_pattern(self, text, regex_pattern):\n",
    "        output_start = None\n",
    "        if self.debug: print(text)\n",
    "        for pattern in regex_pattern:\n",
    "            matches = re.search(pattern, text, re.DOTALL)\n",
    "            \n",
    "            if matches is not None and self.debug: print(pattern, matches.group(1))\n",
    "            if matches is not None: output_start = matches.group(1)\n",
    "        return output_start\n",
    "    \n",
    "    def check_double_start_alphabets(self, text):\n",
    "        '''Use to check in case starting alphabet is longer than one, \n",
    "        ref:https://sites.google.com/site/phasathaionline/hnwy-kar-reiyn-ru2/phyaychnatn'''\n",
    "        #Function that check word in case like ขนม and else \n",
    "        \n",
    "        two_char = self.lead_char_nosound + self.two_char_combine\n",
    "        \n",
    "        max_lcs = 0\n",
    "        if text in two_char: return text\n",
    "        else:\n",
    "            for char in two_char:\n",
    "                if LCSubStr(text, char, len(text), len(char)) > max_lcs: \n",
    "                    max_lcs = LCSubStr(text, char, len(text), len(char))\n",
    "                    max_lcs_char = char\n",
    "            return max_lcs_char\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def check_double_start_sound(self, text):\n",
    "        '''Use to address the case where start alphabets are double and need to split to reflect actual pronunciation \n",
    "        ref:https://sites.google.com/site/phasathaionline/hnwy-kar-reiyn-ru2/phyaychnatn'''\n",
    "        #Function that check word in case like ขนม and else \n",
    "        \n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def remove_karan(self, regex_pattern):\n",
    "        return None\n",
    "        #Write specific function for removing ์"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chat bot ",
   "language": "python",
   "name": "chat_bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
