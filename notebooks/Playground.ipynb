{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: jt\n"
     ]
    }
   ],
   "source": [
    "!jt -t chesterish -fs 12 -nfs 12 -tfs 11 -T -ofs 10 -cellw 1600 -f dejavu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thai_match_pattern():\n",
    "    def __init__(self, start_regex, vowel_regex, end_regex, sound_regex):\n",
    "        self.start_regex = start_regex\n",
    "        self.vowel_regex = vowel_regex\n",
    "        self.end_regex = end_regex\n",
    "        self.sound_regex = sound_regex\n",
    "        \n",
    "    def match_start(self, orig_word):        \n",
    "        matches = re.findall(self.start_regex, orig_word, re.DOTALL)\n",
    "        return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference https://www.geeksforgeeks.org/longest-common-substring-dp-29/\n",
    "# Returns length of longest common  \n",
    "# substring of X[0..m-1] and Y[0..n-1]  \n",
    "def LCSubStr(X, Y, m, n): \n",
    "      \n",
    "    # Create a table to store lengths of \n",
    "    # longest common suffixes of substrings.  \n",
    "    # Note that LCSuff[i][j] contains the  \n",
    "    # length of longest common suffix of  \n",
    "    # X[0...i-1] and Y[0...j-1]. The first \n",
    "    # row and first column entries have no \n",
    "    # logical meaning, they are used only \n",
    "    # for simplicity of the program. \n",
    "      \n",
    "    # LCSuff is the table with zero  \n",
    "    # value initially in each cell \n",
    "    LCSuff = [[0 for k in range(n+1)] for l in range(m+1)] \n",
    "      \n",
    "    # To store the length of  \n",
    "    # longest common substring \n",
    "    result = 0 \n",
    "  \n",
    "    # Following steps to build \n",
    "    # LCSuff[m+1][n+1] in bottom up fashion \n",
    "    for i in range(m + 1): \n",
    "        for j in range(n + 1): \n",
    "            if (i == 0 or j == 0): \n",
    "                LCSuff[i][j] = 0\n",
    "            elif (X[i-1] == Y[j-1]): \n",
    "                LCSuff[i][j] = LCSuff[i-1][j-1] + 1\n",
    "                result = max(result, LCSuff[i][j]) \n",
    "            else: \n",
    "                LCSuff[i][j] = 0\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class thai_subwords():\n",
    "    \"\"\"Design to take input as single Thai token or word and extract start, vowel, end and sound of said token\n",
    "    For additional data regarding different Thai words types and pronunciations, \n",
    "    consult:https://sites.google.com/site/phasathaionline/hnwy-kar-reiyn-ru2/phyaychnatn\"\"\"\n",
    "    def __init__(self, orig_word, debug=False):\n",
    "        self.orig_word = orig_word #Try not to change this value\n",
    "        self._start = ''\n",
    "        self._vowel = ''\n",
    "        self._end = ''\n",
    "        self._sound = ''\n",
    "        self._double_start_sound = False #used to flag with that has two starting alphabets with sound like 'ตลาด = ตะ ลาด'\n",
    "        self._high_lead_low = False #case อักษรสูงนำอักษรต่ำ\n",
    "        self.debug = debug\n",
    "        \n",
    "        #Need to deal with negative lookahead case for word like \"เกรียน\" to correctly extract กร\n",
    "        self.vowels_form = ['ะ', ' ั' ' ็', 'า', ' ิ' , ' ่' , \" ่\" , ' ํ', ' ุ', ' ู', 'เ', 'ใ', 'ไ', 'โ', 'อ', 'ย', 'ว', 'ฤ', 'ฤๅ', 'ฦ', 'ฦๅ']\n",
    "        combine_vowel_regex_1 = '(?!เ.{1,4}ี.*ย)(?!เ.{1,4}ี.*ยะ)(?!เ.{1,4}ื.*อ)(?!เ.{1,4}ื.*อะ)(?!เ.{1,4}.*อะ)(?!เ.{1,4}.*อ)(?!เ.{1,4}.*าะ)'\n",
    "        combine_vowel_regex_2 = '(?!เ.{1,4}.*า)(?!แ.{1,4}.*า)(?!.{1,4}ัวะ)(?!โ.{1,4}.*ะ)'\n",
    "        combine_vowel_regex = combine_vowel_regex_1 + combine_vowel_regex_2\n",
    "        self.start_regex_1 = ['(.{1,4})ะ','(.{1,4})า', '(.{1,4})ิ.*', '(.{1,4})ี.*', '(.{1,4})ึ', '(.{1,4})ื.*', '(.{1,4})ุ.*', '(.{1,4})ู.*', 'เ(.{1,4})็', \n",
    "                            'เ(.{1,4}).*', '(.{1,4}).*อ','แ(.{1,4}).*', '(.{1,4})ั.*', 'โ(.{1,4}).*', '(.{1,4}).*ำ', 'ใ(.{1,4}).*', 'ไ(.{1,4})']\n",
    "        self.start_regex_1  = [combine_vowel_regex+regex for regex in self.start_regex_1]\n",
    "        self.start_regex_2 = ['เ(.{1,4})ี.*ยะ', 'เ(.{1,4})ี.*ย', 'เ(.{1,4})ื.*อะ', 'เ(.{1,4})ื.*อ', 'เ(.{1,4}).*อ', 'เ(.{1,4}).*อะ',\n",
    "                              'เ(.{1,4}).*า',\n",
    "                              'เ(.{1,4}).*าะ','แ(.{1,4}).*ะ','(.{1,4})ัวะ','โ(.{1,4}).*ะ', 'เ(.{1,4})็', 'เ(.{1,4})ิ.*']\n",
    "        self.end_regex_1 = ['\\[REP\\]า(.{1,4})', '\\[REP\\]ิ(.{1,4})', '\\[REP\\]ี(.{1,4})', '\\[REP\\]ึ(.{1,4})', '\\[REP\\]ือ(.{1,4})', \n",
    "                            '\\[REP\\]ุ(.{1,4})', '\\[REP\\]ู(.{1,4})', 'เ\\[REP\\]็(.{1,4})', 'เ\\[REP\\](.{1,4})', '\\[REP\\]อ(.{1,4})',\n",
    "                            'แ\\[REP\\](.{1,4})', '\\[REP\\]ั(.{1,4})', 'โ\\[REP\\](.{1,4})','\\[REP\\]ำ(.{1,4})', 'ใ\\[REP\\](.{1,4})', \n",
    "                            'ไ\\[REP\\](.{1,4})']\n",
    "        self.end_regex_2 = ['เ\\[REP\\]ีย(.{1,4})', 'เ\\[REP\\]ือ(.{1,4})', 'เ\\[REP\\]อ(.{1,4})', 'เ\\[REP\\]อะ(.{1,4})','เ\\[REP\\]า(.{1,4})']\n",
    "        \n",
    "        self.start_regex  = self.start_regex_1 + self.start_regex_2 \n",
    "        self.end_regex  = self.end_regex_1 + self.end_regex_2 \n",
    "        #self.vowel_regex = vowel_regex\n",
    "        #self.end_regex = end_regex\n",
    "        self.sound_regex = ['(่)', '(้)', '.(๊)','()๋']\n",
    "        \n",
    "        #initialize the special character cases\n",
    "        #คำควบแท้\n",
    "        self.two_char_combine = ['กร','กล', 'กว', 'คร', 'ขร', 'คล', 'ขล','คว', 'ขว', 'ตร', 'ปร', 'ปล', 'พร', 'พล' ,'ผล',\n",
    "                   'บร','บล','ดร','ฟร','ฟล','ทร','จร','ซร','ปร','สร']\n",
    "        #คำนำ\n",
    "        self.lead_char_nosound = ['อย','หง','หญ','หน','หม','หย', 'หร','หล','หว']\n",
    "        #อักษรสูงนำอักษรต่ำ\n",
    "        self._lead_char_high_low = ['ขน', 'ขม','สม','สย','สน','ขย','ฝร','ถล','ผว','ตน','จม','ตล',]\n",
    "        #อักษรสูงนำอักษรกลาง\n",
    "        self._high_char_high_medium = ['ผท','ผด','ผก','ผอ','ผช']\n",
    "        \n",
    "        \n",
    "    # using property decorator \n",
    "    @property\n",
    "    def start(self): \n",
    "        #print(\"getter method called\") \n",
    "        temp_start = self.match_pattern(self.orig_word, self.start_regex)\n",
    "        if len(temp_start)==1: return temp_start\n",
    "        else: \n",
    "            return self.check_double_start_alphabets(temp_start)\n",
    "        #return self.match_pattern(self.orig_word, self.start_regex)\n",
    "    \n",
    "    @property\n",
    "    def sound(self):\n",
    "        if self.match_pattern(self.orig_word, self.sound_regex) is None: return ''\n",
    "        return self.match_pattern(self.orig_word, self.sound_regex)\n",
    "    \n",
    "    @property\n",
    "    def vowel(self):\n",
    "        return self.orig_word.replace(self.sound,'').replace(self.start,'[REP]',1) #[REP] will be used for conversion to Lu/Ru\n",
    "#     def vowel(self):\n",
    "#         return self.orig_word.replace(self.sound,'').replace(self.end,'').replace(self.start,'[REP]',1) #[REP] will be used for conversion to Lu/Ru\n",
    "    \n",
    "    @property #might not need this one in final application as we need vowel\n",
    "    def end(self):\n",
    "        if self.match_pattern(self.vowel, self.end_regex) not in self.vowels_form: \n",
    "            return self.match_pattern(self.vowel, self.end_regex)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "#     # a setter function \n",
    "#     @start.setter \n",
    "#     def start(self): \n",
    "#         print(\"setter method called\") \n",
    "#         self._start = match_pattern(self.start_regex)\n",
    "    \n",
    "    def match_pattern(self, text, regex_pattern):\n",
    "        output_start = None\n",
    "        if self.debug: print(text)\n",
    "        for pattern in regex_pattern:\n",
    "            matches = re.search(pattern, text, re.DOTALL)\n",
    "            \n",
    "            if matches is not None and self.debug: print(pattern, matches.group(1))\n",
    "            if matches is not None: output_start = matches.group(1)\n",
    "        return output_start\n",
    "    \n",
    "    def check_double_start_alphabets(self, text):\n",
    "        '''Use to check in case starting alphabet is longer than one, \n",
    "        ref:https://sites.google.com/site/phasathaionline/hnwy-kar-reiyn-ru2/phyaychnatn'''\n",
    "        #Function that check word in case like ขนม and else \n",
    "        \n",
    "        two_char = self.lead_char_nosound + self.two_char_combine\n",
    "        \n",
    "        max_lcs = 0\n",
    "        if text in two_char: return text\n",
    "        else:\n",
    "            for char in two_char:\n",
    "                if LCSubStr(text, char, len(text), len(char)) > max_lcs: \n",
    "                    max_lcs = LCSubStr(text, char, len(text), len(char))\n",
    "                    max_lcs_char = char\n",
    "            return max_lcs_char\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def check_double_start_sound(self, text):\n",
    "        '''Use to address the case where start alphabets are double and need to split to reflect actual pronunciation \n",
    "        ref:https://sites.google.com/site/phasathaionline/hnwy-kar-reiyn-ru2/phyaychnatn'''\n",
    "        #Function that check word in case like ขนม and else \n",
    "        \n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def remove_karan(self, regex_pattern):\n",
    "        return None\n",
    "        #Write specific function for removing ์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ปล\n",
      "[REP]าด\n",
      "ด\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtest = thai_subwords('ปลาด', debug=False)\n",
    "print(subtest.start)\n",
    "print(subtest.vowel)\n",
    "print(subtest.end)\n",
    "subtest.sound\n",
    "\n",
    "#subtest = thai_subwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import syllable_tokenize #use syllable level as it should be easier for Lu conversion\n",
    "class Lu_translators():\n",
    "    def __init__(self, sentence, syllable_tokenizer=syllable_tokenize):\n",
    "        self.orig_sen = sentence\n",
    "        self.orig_tokens = syllable_tokenizer(self.orig_sen)\n",
    "        self.thai_to_lu_dict = {}\n",
    "        #get subwords\n",
    "        self.sub_words = [thai_subwords(token) for token in self.orig_tokens if token != ' ']\n",
    "    \n",
    "    def thai_to_lu(self, sub_words):\n",
    "        '''Does not use self.subwords in case we want to apply to other objects\n",
    "        input = list of sub_words object'''\n",
    "        \n",
    "        thai_to_lu_dict = {}\n",
    "        for token in sub_words:\n",
    "            #print(token.orig_word)\n",
    "            ending = token.end if token.end is not None else ''\n",
    "            start_rep = 'ซ' if token.start == 'ล' or token.start == 'ร' else 'ล'   #start replacement, can be ล or ซ\n",
    "            if '[REP]ู' in token.vowel:\n",
    "                lu = token.vowel.replace('[REP]', start_rep) + token.start + 'ี' + ending\n",
    "            elif '[REP]ุ' in token.vowel:\n",
    "                lu = token.vowel.replace('[REP]', start_rep) + token.start + 'ิ' + ending\n",
    "            else:\n",
    "                lu = token.vowel.replace('[REP]', start_rep) + token.start + 'ู' + ending\n",
    "            thai_to_lu_dict[token.orig_word] = lu\n",
    "        return thai_to_lu_dict\n",
    "    \n",
    "    def check_longshort_sound():\n",
    "        return None\n",
    "        #Need to write function to check เสียงสั้นเสียงยาว\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ไป', 'ไหน', 'ดี']\n",
      "{'ไป': 'ไลปู', 'ไหน': 'ไลหนู', 'ดี': 'ลีดู'}\n"
     ]
    }
   ],
   "source": [
    "test_lu = Lu_translators(\"ไปไหนดี\")\n",
    "print(test_lu.orig_tokens)\n",
    "thai_to_lu_dict = test_lu.thai_to_lu(test_lu.sub_words)\n",
    "# for sub in test_lu.sub_words:\n",
    "#     print(sub.orig_word)\n",
    "#     print(sub.start, sub.vowel)\n",
    "print(thai_to_lu_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['สวย']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-860eeeccb42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_lu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLu_translators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"สวย\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthai_to_lu_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_lu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthai_to_lu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# for sub in test_lu.sub_words:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(sub.orig_word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-66280ab666df>\u001b[0m in \u001b[0;36mthai_to_lu\u001b[0;34m(self, sub_words)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#print(token.orig_word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mstart_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ซ'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ล'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ร'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'ล'\u001b[0m   \u001b[0;31m#start replacement, can be ล or ซ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'[REP]ู'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aa54552874a0>\u001b[0m in \u001b[0;36mend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m \u001b[0;31m#might not need this one in final application as we need vowel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_regex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowels_form\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aa54552874a0>\u001b[0m in \u001b[0;36mvowel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvowel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'[REP]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[REP] will be used for conversion to Lu/Ru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;31m#     def vowel(self):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#         return self.orig_word.replace(self.sound,'').replace(self.end,'').replace(self.start,'[REP]',1) #[REP] will be used for conversion to Lu/Ru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aa54552874a0>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#print(\"getter method called\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtemp_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtemp_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_double_start_alphabets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "test_lu = Lu_translators(\"สวย\")\n",
    "print(test_lu.orig_tokens)\n",
    "thai_to_lu_dict = test_lu.thai_to_lu(test_lu.sub_words)\n",
    "# for sub in test_lu.sub_words:\n",
    "#     print(sub.orig_word)\n",
    "#     print(sub.start, sub.vowel)\n",
    "print(thai_to_lu_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ตด', 'ดัง', 'มาก']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d63c14be3a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_lu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLu_translators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ตดดังมาก\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthai_to_lu_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_lu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthai_to_lu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# for sub in test_lu.sub_words:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(sub.orig_word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-66280ab666df>\u001b[0m in \u001b[0;36mthai_to_lu\u001b[0;34m(self, sub_words)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#print(token.orig_word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mstart_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ซ'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ล'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ร'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'ล'\u001b[0m   \u001b[0;31m#start replacement, can be ล or ซ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'[REP]ู'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aa54552874a0>\u001b[0m in \u001b[0;36mend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m \u001b[0;31m#might not need this one in final application as we need vowel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_regex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowels_form\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aa54552874a0>\u001b[0m in \u001b[0;36mvowel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvowel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'[REP]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[REP] will be used for conversion to Lu/Ru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;31m#     def vowel(self):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#         return self.orig_word.replace(self.sound,'').replace(self.end,'').replace(self.start,'[REP]',1) #[REP] will be used for conversion to Lu/Ru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aa54552874a0>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#print(\"getter method called\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtemp_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtemp_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_double_start_alphabets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "test_lu = Lu_translators(\"ตดดังมาก\")\n",
    "print(test_lu.orig_tokens)\n",
    "thai_to_lu_dict = test_lu.thai_to_lu(test_lu.sub_words)\n",
    "# for sub in test_lu.sub_words:\n",
    "#     print(sub.orig_word)\n",
    "#     print(sub.start, sub.vowel)\n",
    "print(thai_to_lu_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat bot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
